# OMS Chat Bot - Environment Configuration Sample
# Copy this file to .env and fill in actual values for your environment

# ============================================================================
# APPLICATION SETTINGS
# ============================================================================

# App environment (development, staging, production)
# - development: enables /docs endpoint, verbose logging
# - production: disables debug endpoints, stricter error handling
APP_ENV=development

# Whether the app is running in production
APP_IS_PRODUCTION=false

# ============================================================================
# DATABASE - MONGODB
# ============================================================================

# MongoDB connection URI
# Format: mongodb+srv://username:password@cluster.mongodb.net/database_name
# Local development: mongodb://localhost:27017/oms_chatbot
MONGODB_URI=mongodb://localhost:27017/oms_chatbot

# MongoDB database name (optional, defaults to database in URI)
# Used when creating collections and migrations
MONGODB_DATABASE_NAME=oms_chatbot

# MongoDB connection timeout (seconds)
# How long to wait before giving up on MongoDB connection at startup
MONGODB_CONNECTION_TIMEOUT=8

# MongoDB operation timeout (seconds)
# How long to wait for individual operations (queries, inserts, etc)
MONGODB_OPERATION_TIMEOUT=30

# ============================================================================
# DATABASE - QDRANT (Vector Search)
# ============================================================================

# Qdrant server URL
# Local development: http://localhost:6333
# Docker: http://qdrant:6333
QDRANT_URL=http://localhost:6333

# Qdrant API key (optional, only if Qdrant is secured)
# Leave empty for local/unsecured instances
QDRANT_API_KEY=

# Qdrant collection name for embeddings
# This collection stores document embeddings for semantic search
QDRANT_COLLECTION_NAME=documents

# Qdrant connection timeout (seconds)
QDRANT_CONNECTION_TIMEOUT=6

# ============================================================================
# DATABASE - REDIS (Caching & Job Queue)
# ============================================================================

# Redis connection URL
# Format: redis://[:password]@host:port/db
# Local development: redis://localhost:6379/0
# Docker: redis://redis:6379/0
REDIS_URL=redis://localhost:6379/0

# Redis connection timeout (seconds)
REDIS_CONNECTION_TIMEOUT=4

# Redis key prefix (optional, for multi-app Redis instances)
# If provided, all keys will be prefixed with this value
REDIS_KEY_PREFIX=oms_

# ============================================================================
# DATABASE - ARANGODB (Graph Database)
# ============================================================================

# ArangoDB server URL
# Format: http://host:port
# Local development: http://localhost:8529
# Docker: http://arangodb:8529
ARANGODB_URL=http://localhost:8529

# ArangoDB username (default: root)
ARANGODB_USERNAME=root

# ArangoDB password
ARANGODB_PASSWORD=

# ArangoDB database name
ARANGODB_DATABASE_NAME=oms_chatbot

# ArangoDB connection timeout (seconds)
ARANGODB_CONNECTION_TIMEOUT=6

# ============================================================================
# LLM - Language Model
# ============================================================================

# LLM API base URL
# LMStudio (default): http://192.168.56.1:1234/v1 (from guest VM perspective)
# OpenAI: https://api.openai.com/v1
# Local: http://localhost:8000/v1
LMSTUDIO_API_URL=http://192.168.56.1:1234/v1

# LLM API key (leave empty for LMStudio)
# Required for OpenAI or other commercial APIs
LLM_API_KEY=

# LLM model name (must match model loaded in LMStudio)
# Examples: mistral-7b, neural-chat-7b, openhermes-2.5-mistral-7b
LLM_MODEL_NAME=mistral-7b

# Maximum tokens for LLM output
# Prevents unbounded response generation
# Typical range: 512-2048 (depends on model and use case)
MAX_LLM_OUTPUT_TOKENS=2048

# Maximum context tokens for LLM input
# Total tokens available to include document chunks
# Typical range: 2000-4000
MAX_CONTEXT_TOKENS=2000

# LLM temperature (controls randomness)
# 0.0 = deterministic, 1.0 = very random
# Typical range: 0.2-0.8 (lower for factual, higher for creative)
LLM_TEMPERATURE=0.3

# LLM top_p parameter (nucleus sampling)
# Typical range: 0.8-0.95
LLM_TOP_P=0.95

# ============================================================================
# EMBEDDING & RETRIEVAL - PHASE 2 (Document Training)
# ============================================================================

# Force LLM to reference documents (Phase 2 Core Feature)
# When true, LLM is instructed to cite and use uploaded documents
# When false, LLM operates without document constraints
FORCE_DOCUMENT_USAGE=true

# Validate that responses cite documents (Phase 2 Validation)
# When true, responses are scored based on:
# - Presence of citations [1], [2], etc
# - Citation count matches reference usage
# - No generic phrases without backing
VALIDATE_DOCUMENT_USAGE=true

# Require minimum citations in responses (Phase 2 Quality Gate)
# Responses with fewer than this many citations are marked invalid
# Typical range: 1-3 (balance between requirement and flexibility)
REQUIRE_CITATIONS=true

# Minimum citation count per response (Phase 2 Quality Metric)
# If response has fewer citations, it's marked invalid
# Set to 1 for "at least 1 citation required"
# Set to 0 to allow responses without citations
MIN_CITATION_COUNT=1

# Minimum similarity threshold for document retrieval
# Only document chunks with similarity > threshold are included in context
# Typical range: 0.3-0.7 (lower = more lenient, higher = stricter)
MIN_SIMILARITY_THRESHOLD=0.3

# Top-K documents to retrieve from vector database
# How many most-similar document chunks to include in context
# Typical range: 5-20 (balance between relevance and context size)
TOP_K_RETRIEVAL=10

# ============================================================================
# IMAGE & MEDIA EXTRACTION - PHASE 2 (Optional Features)
# ============================================================================

# Extract images from PDF documents during ingestion (Phase 2 Feature)
# When true, PDFs are scanned and images are extracted automatically
# Images are stored in MongoDB and offered as inline media suggestions
# When false, only text is extracted from PDFs
EXTRACT_IMAGES_FROM_PDF=true

# Extract video links (YouTube, Vimeo, etc) from document text (Phase 2 Feature)
# When true, the system identifies and suggests embedded video URLs
# When false, only text content is processed
EXTRACT_VIDEO_LINKS=true

# Suggest related media in responses (Phase 2 Feature)
# When true, system suggests images, videos, and links related to response
# When false, only text responses are generated
SUGGEST_RELATED_MEDIA=true

# Maximum number of media suggestions per response (Phase 2 Limit)
# Prevents overwhelming users with too many media items
# Typical range: 3-10
MAX_SUGGESTED_MEDIA=5

# Chunk size for document splitting (Retrieval Optimization)
# Larger chunks = more context per retrieval, fewer chunks needed
# Smaller chunks = more specific matches, higher precision
# Typical range: 500-1500
CHUNK_SIZE=750

# Chunk overlap between adjacent chunks (Retrieval Optimization)
# Prevents information loss at chunk boundaries
# Typical range: 50-200
CHUNK_OVERLAP=100

# ============================================================================
# DOCUMENT INGESTION - WORKER QUEUE
# ============================================================================

# Enable document ingestion worker (Phase 2 Async Processing)
# When true, uploaded documents are processed asynchronously via Redis queue
# When false, documents are processed synchronously (slower, simpler)
ENABLE_INGEST_WORKER=true

# Redis queue name for document ingestion tasks
# Tasks are stored here and processed by ingest worker
INGEST_QUEUE_NAME=document_ingestion

# Maximum time to process a single document (seconds)
# If document processing takes longer, task is marked failed
INGEST_TASK_TIMEOUT=300

# Number of retries for failed ingestion tasks
# If document processing fails, retry this many times
INGEST_TASK_RETRIES=2

# ============================================================================
# FEATURE FLAGS - EXPERIMENTAL/OPTIONAL
# ============================================================================

# Use graph-based search (Neo4j/ArangoDB relationships)
# When true, document relationships are used for enhanced retrieval
# When false, only semantic similarity search is used
USE_GRAPH_SEARCH=false

# Enable response streaming (chunked SSE responses)
# When true, /chat/query streams tokens as they're generated
# When false, response is returned all at once
ENABLE_STREAMING=false

# Enable detailed logging (very verbose output)
# When true, logs include trace-level details from all services
# When false, only info/warning/error level logs
ENABLE_DEBUG_LOGGING=false

# ============================================================================
# CORS & SECURITY (Frontend Integration)
# ============================================================================

# Frontend URL (for CORS configuration)
# Used to allow cross-origin requests from frontend
# Development: http://localhost:3000
# Production: https://yourdomain.com
FRONTEND_URL=http://localhost:3000

# Backend API URL (for frontend API client)
# URL that frontend uses to reach backend
# Development: http://localhost:8000
# Production: https://api.yourdomain.com
BACKEND_URL=http://localhost:8000

# ============================================================================
# NOTES & MIGRATION GUIDE
# ============================================================================
#
# Phase 2 Core Settings (Required for Document Training):
# - FORCE_DOCUMENT_USAGE=true              # Ensures LLM uses documents
# - VALIDATE_DOCUMENT_USAGE=true           # Scores response quality
# - REQUIRE_CITATIONS=true                 # Quality gate
# - MIN_CITATION_COUNT=1                   # Minimum citations needed
#
# Phase 2 Media Features (Optional, can be disabled):
# - EXTRACT_IMAGES_FROM_PDF=true           # Auto-extract PDF images
# - EXTRACT_VIDEO_LINKS=true               # Find embedded videos
# - SUGGEST_RELATED_MEDIA=true             # Media recommendations
# - MAX_SUGGESTED_MEDIA=5                  # Limit suggestions
#
# Database Configuration:
# - All databases are optional (graceful degradation)
# - If MONGODB_URI is empty, in-memory storage is used
# - If QDRANT_URL is empty, semantic search is disabled
# - If REDIS_URL is empty, synchronous processing only
#
# Development vs Production:
# - Set APP_ENV=development for local testing (enables /docs, verbose logs)
# - Set APP_ENV=production for deployment (strict error handling, no debug endpoints)
# - For production: use environment-specific .env files (.env.production)
#
# Example .env file for local development:
# ```
# APP_ENV=development
# MONGODB_URI=mongodb://localhost:27017/oms_chatbot
# QDRANT_URL=http://localhost:6333
# REDIS_URL=redis://localhost:6379/0
# LMSTUDIO_API_URL=http://192.168.56.1:1234/v1
# FORCE_DOCUMENT_USAGE=true
# VALIDATE_DOCUMENT_USAGE=true
# ```
